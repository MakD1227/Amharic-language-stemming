{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stem word of the text  ['ላለፉት ጥቂት ለማይባሉ', ' ወራት . 9 ', 'የክስ ቻርጅ የለ', ' በቃ ዘብጥያ ወደ ቤትህ ሂድ']  is  ['ለፋ ጥቂት ተባለ', 'ወር', 'ክስ ቻርጅ የለ', 'እቃ ዘብጥያ ወደ ቤት ሄደ']\n",
      "\n",
      "\n",
      "Evaluation of Gesser stemmer and customized stemmers: amharicStemmer() and corpus stemmer\n",
      "\n",
      "Out put of Gesser stemmer:  [{'POS': 'n', 'lemma': 'ቤት|bet', 'root': 'ቤት|bet', 'gloss': 'house', 'gram': [-acc,cnj=None,+def,-dis,-gen,-itu,-plr,pos=n,poss=[+expl,-fem,-p1,+p2,-plr],prep=None,-prp,t=[eng=house],v=None]}]\n",
      "\n",
      "\n",
      "Out put of amharicWordStemmer: ቤት\n",
      "\n",
      "\n",
      "Out put of amharicCorpusStemmer: ['ለፋ ጥቂት ተባለ', 'ወር', 'ክስ ቻርጅ የለ', 'እቃ ዘብጥያ ወደ ቤት ሄደ']\n"
     ]
    }
   ],
   "source": [
    "#import neccessary packages \n",
    "\n",
    "#importing hornmorpho packas as hm\n",
    "#if unable to install  the hornmorpho(hm) package using 'pip', download zip file@https://github.com/hltdi/HornMorpho.git\n",
    "# unzip it and save inside current path(the path/directory where other packages are installed,then \n",
    "# change its name(folder name) to 'hm' in the distination directory, where it is installed\n",
    "from hm import anal#import anal function from package hornmorpho(hm)\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#part I\n",
    "\"\"\"\n",
    "define/declartion methods for text preprocessing such as:\n",
    "#removePunct(), #removeAsciiandNumbers(),#removeEmoj()\n",
    "these function takes only 1 D text i.e sentence or word only, doesn't support list of sentences  \n",
    "\"\"\"\n",
    "\n",
    "#removing punctuations and special characters\n",
    "def removePunct(text_input):    \n",
    "        am_punc='[፨፧፦!፥፤፣፣።፡,():;.]+'\n",
    "        clean_txt = re.sub(am_punc, ' ',text_input)\n",
    "        clean_txt=re.sub('[\\(\\)[\\]\\{\\}|]',' ',clean_txt)\n",
    "        #replacing any existance of special character or punctuation to null  \n",
    "        special_char=\"[@#$%^&ǝ=?×!,;:_.`'\\'/+*<>\\\"¤—„\\-®¯™ṣčṣṣᵂᵂṭᵂč̣ǝwannǝt¡¡\\x10»€«·‘0e1b§”¬¦…\"\"f÷\\~¨©±¥£¶–°•˜’“|]\"\n",
    "        clean_txt= re.sub(special_char,' ',clean_txt) \n",
    "        return clean_txt\n",
    "def removeAsciiandNumbers(text_input):\n",
    "        #remove all ascii characters and Arabic and ge'ez numbers\n",
    "        #your input should be text, cats its data type if it is not text\n",
    "        rm_num_and_ascii=re.sub('[A-Za-z0-9]','',text_input)\n",
    "        rm_geez_num=re.sub('[\\'\\u1369-\\u137C\\']+','',rm_num_and_ascii)\n",
    "        return rm_geez_num\n",
    "    \n",
    "#remove emoj\n",
    "def removeEmoj(text_input):\n",
    "        #your input should be text, cats its data type if it is not text\n",
    "        #remove imojs\n",
    "        RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "        clean_text = RE_EMOJI.sub(r'',text_input)\n",
    "        emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\"# emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\" # flags\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'',clean_text)\n",
    "    \n",
    "#pack all the function presented in the above \n",
    "def cleanDocument(text_input): # takes ssentence or paragraph and return cleaned text\n",
    "        #if the input data is list it must be converted into string to preprocess        \n",
    "        cleaned_text=removePunct(text_input)\n",
    "        cleaned_text=removeAsciiandNumbers(cleaned_text)\n",
    "        cleaned_text=removeEmoj(cleaned_text)        \n",
    "        return cleaned_text\n",
    "\n",
    "#part II    \n",
    "\"\"\" \n",
    "define functions such as: #characterNormalize(),#spellForwardCorrect(), #spellReverseCorrect()\n",
    "#these function takes only 1 D text i.e sentence or word only, doesn't support list of sentences\n",
    "\"\"\"\n",
    "#normalizting characters \n",
    "def characterNormalize(text_input):\n",
    "        #your input should be text, cats its data type if it is not text\n",
    "        #normalize ceach characters\n",
    "        #simlar sound but different morphes\n",
    "        rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',text_input)\n",
    "        rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
    "        rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
    "        rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
    "        rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
    "        rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
    "        rep7=re.sub('[ሠ]','ሰ',rep6)\n",
    "        rep8=re.sub('[ሡ]','ሱ',rep7)\n",
    "        rep9=re.sub('[ሢ]','ሲ',rep8)\n",
    "        rep10=re.sub('[ሣ]','ሳ',rep9)\n",
    "        rep11=re.sub('[ሤ]','ሴ',rep10)\n",
    "        rep12=re.sub('[ሥ]','ስ',rep11)\n",
    "        rep13=re.sub('[ሦ]','ሶ',rep12)\n",
    "        rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
    "        rep15=re.sub('[ዑ]','ኡ',rep14)\n",
    "        rep16=re.sub('[ዒ]','ኢ',rep15)\n",
    "        rep17=re.sub('[ዔ]','ኤ',rep16)\n",
    "        rep18=re.sub('[ዕ]','እ',rep17)\n",
    "        rep19=re.sub('[ዖ]','ኦ',rep18)\n",
    "        rep20=re.sub('[ጸ]','ፀ',rep19)\n",
    "        rep21=re.sub('[ጹ]','ፁ',rep20)\n",
    "        rep22=re.sub('[ጺ]','ፂ',rep21)\n",
    "        rep23=re.sub('[ጻ]','ፃ',rep22)\n",
    "        rep24=re.sub('[ጼ]','ፄ',rep23)\n",
    "        rep25=re.sub('[ጽ]','ፅ',rep24)\n",
    "        rep26=re.sub('[ጾ]','ፆ',rep25)\n",
    "        #Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል  \n",
    "        rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
    "        rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
    "        rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
    "        rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
    "        rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
    "        rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
    "        rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
    "        rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
    "        rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
    "        rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
    "        rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
    "        rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
    "        rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
    "        rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
    "        rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
    "        rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
    "        rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
    "        rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
    "        rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
    "        rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
    "        rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
    "        rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ  \n",
    "        return rep48\n",
    "\n",
    "#correcting misspelled words   \n",
    "def spellForwardCorrect(token_input):#helps to correct miss spelled character \n",
    "        rep1=re.sub(('ወች'),'ዎች',token_input)\n",
    "        rep2=re.sub('[ዉ]','ው',rep1)\n",
    "        rep3=re.sub('[ጂ]','ጅ',rep2)\n",
    "        rep4=re.sub('[ቸ]','ቼ',rep3)\n",
    "        rep5=re.sub('[የ]','ዬ',rep4)\n",
    "        rep6=re.sub('[ጀ]','ጄ',rep5)\n",
    "        rep7=re.sub('[ኜ]','ኘ',rep6)\n",
    "        rep8=re.sub('[ሽ]','ሺ',rep7)\n",
    "        rep9=re.sub('[ጨ]','ጬ',rep8)\n",
    "        rep10=re.sub('[ጪ]','ጭ',rep9)\n",
    "        rep11=re.sub('[ዥ]','ዢ',rep10)\n",
    "        rep12=re.sub('[ዪ]','ይ',rep11)\n",
    "        return rep12\n",
    "    \n",
    "def spellReverseCorrect(token_input): #helps to correct miss spelled character\n",
    "        #reversese vesion of  spellForwardCorrect() funcspellForwardCorrection      \n",
    "        rep1=re.sub(('ኚ'),'ኝ',token_input)\n",
    "        rep2=re.sub('[ው]','ዉ',rep1)\n",
    "        rep3=re.sub('[ጅ]','ጂ',rep2)\n",
    "        rep4=re.sub('[ቼ]','ቸ',rep3)\n",
    "        rep5=re.sub('[ዬ]','የ',rep4)\n",
    "        rep6=re.sub('[ጄ]','ጀ',rep5)\n",
    "        rep7=re.sub('[ኜ]','ኘ',rep6)\n",
    "        rep8=re.sub('[ሽ]','ሺ',rep7)\n",
    "        rep9=re.sub('[ጬ]','ጨ',rep8)\n",
    "        rep10=re.sub('[ጭ]','ጪ',rep9)\n",
    "        rep11=re.sub('[ዢ]','ዥ',rep10)\n",
    "        rep12=re.sub('[ይ]','ዪ',rep11)\n",
    "        return rep12\n",
    "\n",
    "#part III\n",
    "#stemmer prepartion\n",
    "\"\"\"\n",
    "#define stemer which custumize output of hornmorpho stemmer\n",
    "# hornmorph stemmer is developed by Michael Gesser, and \n",
    "#the stemer is also called Gesser stemmer\n",
    "#anal() method of gesser stemmer returns part of speech.\n",
    "#hence special_char and ummeccssary words should remove\n",
    "# amharicStemmer() return only stem of the word by utilizing cleanDocument() function defined above\n",
    "\"\"\"\n",
    "#amharicStemer() takes word and return its stem\n",
    "#in amharicWordStemer() part of speech tag(pos) list is removed \n",
    "#while corpusStemmer takes corpus as argument and return stem of a corpus\n",
    "def amharicWordStemmer(token_input):       \n",
    "        pos_list=anal('am',token_input,raw=True)\n",
    "        stem=cleanDocument(str(pos_list))\n",
    "        stem=stem.split()\n",
    "        if stem !=[]:\n",
    "            return stem[0]\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    " #takes corpus, list of sentence(s),phrases or word(s) and returns stem \n",
    "def amharicCorpusStemmer(corpus):   \n",
    "    cleaned_text=[]# create empty list to store pcleaned text later\n",
    "    stemed_text=[]\n",
    "    for i in range(len(corpus)):\n",
    "        #clean the text from noises such as punctuation marks\n",
    "        cleaned_text.append(cleanDocument(corpus[i]))\n",
    "\n",
    "    for i in range(len(cleaned_text)):\n",
    "        strg=''\n",
    "        for token_in in cleaned_text[i].split():\n",
    "                    stem=amharicWordStemmer(token_in)\n",
    "                    if(stem==''):\n",
    "                        stem=amharicWordStemmer(characterNormalize(token_in))\n",
    "                        if(stem==''):\n",
    "                            stem=amharicWordStemmer(spellForwardCorrect(token_in))                    \n",
    "                            if(stem==''):\n",
    "                                stem=amharicWordStemmer(spellReverseCorrect(token_in))\n",
    "                    if(stem!=''):\n",
    "                       strg=strg+stem+' '\n",
    "                    else:\n",
    "                      #take the word as it is if the word is not stemmed\n",
    "                      strg=strg+token_in+' '\n",
    "        stemed_text.append(strg[:-1])\n",
    "    return stemed_text\n",
    "\n",
    "\n",
    "#Part IV how to use:\n",
    "#conculusion:\n",
    "\"\"\" \n",
    " we can use amharicCorpusStemmer() to stem a corpus by passing 'corpus' argument to it\n",
    " amharicCorpusStemmer(corpus), corpus parameter could be: word, list of words(pandaSereies), list of of senences, or dataFrame\n",
    " \"\"\"\n",
    "#using amharicCorpusStemmer() \n",
    "corpus=['ላለፉት ጥቂት ለማይባሉ', ' ወራት . 9 ', 'የክስ ቻርጅ የለ', ' በቃ ዘብጥያ ወደ ቤትህ ሂድ']\n",
    "stem=amharicCorpusStemmer(corpus)\n",
    "print('The stem word of the text ',corpus,' is ',stem) \n",
    "print() \n",
    "#part V: Evaluation \n",
    "#Evaluation of Gesser stemmer and customized stemmers: amharicStemmer() and corpus stemmer\n",
    "token_in='ቤትህ'\n",
    "corpus=['ላለፉት ጥቂት ለማይባሉ', ' ወራት . 9 ', 'የክስ ቻርጅ የለ', ' በቃ ዘብጥያ ወደ ቤትህ ሂድ']\n",
    "print() \n",
    "print('Evaluation of Gesser stemmer and customized stemmers: amharicStemmer() and corpus stemmer')\n",
    "print() \n",
    "print('Out put of Gesser stemmer: ', anal('am',token_in,raw=True))\n",
    "print() \n",
    "print() \n",
    "print('Out put of amharicWordStemmer:', amharicWordStemmer(token_in))\n",
    "print()\n",
    "print() \n",
    "print('Out put of amharicCorpusStemmer:', amharicCorpusStemmer(corpus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'እለት'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amharicStemer('እለት')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
